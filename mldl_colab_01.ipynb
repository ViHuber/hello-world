{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "mldl_colab_01.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ViHuber/hello-world/blob/master/mldl_colab_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_FRWWQfKmMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-*- coding: utf-8 -*-"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbxblN7WKmMq",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"https://github.com/GitiHubi/courseMLDL/blob/master/lab_01/hsg_logo.png?raw=1\">\n",
        "\n",
        "###  Lab 01 - \"Introduction to the Lab Environment\"\n",
        "\n",
        "Introduction to ML and DL, University of St. Gallen, Autumn Term 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc5ZIL3zKmMs",
        "colab_type": "text"
      },
      "source": [
        "The lab environment of the **\"Introduction to Machine Learning and Deep Learning\"** course is powered by Jupyter Notebooks (https://jupyter.org), which allow one to perform a great deal of data analysis and statistical validation. In this first lab, we want to touch on the basic concepts and techniques of such notebooks. Furthermore, its capabilities will be demonstrated based on a few simple and introductory examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFeQ-v-rKmMu",
        "colab_type": "text"
      },
      "source": [
        "### Lab Objectives:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXiT_GOoKmMv",
        "colab_type": "text"
      },
      "source": [
        "After today's lab, you should be able to:\n",
        "    \n",
        "> 1. Understand the general workflow, structure, and functionality of **Jupyter** notebooks.\n",
        "> 2. Import and apply python data science libraries such as **numpy** and **pandas**. \n",
        "> 3. Understand how the **python** programming language can be utilized to manipulate and analyze financial data.\n",
        "> 4. Download arbitrary stock market and financial data using the **Quandl** Python API.\n",
        "> 5. Use the **Matplotlib** library to visualize data as well as analytical results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdT_Ai_mKmMw",
        "colab_type": "text"
      },
      "source": [
        "Note: The content of this first lab is inspired by the Quantopian lecture series ( https://www.quantopian.com ). If you are interested to learn more about financial data science and/or algorithmic trading their lectures are a great resource to get you started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-nhEy2rKmMx",
        "colab_type": "text"
      },
      "source": [
        "### 1. Jupyter Notebook Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7YxEuvYKmMx",
        "colab_type": "text"
      },
      "source": [
        "#### Code Cells vs. Text Cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAeCsZaAKmMy",
        "colab_type": "text"
      },
      "source": [
        "As you can see, each cell can be either code or text. To select between them, choose from the 'Cell Type' dropdown menu on the top left."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmBtGpfRKmMz",
        "colab_type": "text"
      },
      "source": [
        "Hello World!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_JCwY9bKmMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "1 + 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm4GoEVYKmM3",
        "colab_type": "text"
      },
      "source": [
        "#### Executing a Command"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J-AGOU0KmM4",
        "colab_type": "text"
      },
      "source": [
        "A code cell will be evaluated when you press **'Run'**, or when you press the shortcut, shift-enter. Evaluating a cell evaluates each line of code in sequence, and prints the results of the last line below the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti-dsK8CKmM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "40 + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQy0xzkhKmM7",
        "colab_type": "text"
      },
      "source": [
        "Sometimes there is no result to be printed, as is the case with the following assignment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA_KXKp0KmM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8angPFgXKmNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg_JKUjcKmNC",
        "colab_type": "text"
      },
      "source": [
        "Remember that only the result from the last line is printed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkFkVLp9KmND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "2 + 2\n",
        "3 + 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gooid_fKmNI",
        "colab_type": "text"
      },
      "source": [
        "However, you can print whichever lines you want using the print statement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXURsRBLKmNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(2 + 2)\n",
        "3 + 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyQdYJv8KmNK",
        "colab_type": "text"
      },
      "source": [
        "#### Knowing When a Cell is Running"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KxOFPD6KmNL",
        "colab_type": "text"
      },
      "source": [
        "While a cell is running, a **[*]** will be displayed on the left of the respective cell. When a cell has yet to be executed, **[ ]** will be displayed. When it has been run, a number will display indicating the order in which it was run during the execution of the notebook **[5]**. Try on this cell and note what is happening:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5Ppf8wwKmNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# take some time to run something\n",
        "c = 0\n",
        "for i in range(10000000):\n",
        "    c = c + i\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGV0xFVsKmNQ",
        "colab_type": "text"
      },
      "source": [
        "### 2. Importing Python Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpLNRjGzKmNR",
        "colab_type": "text"
      },
      "source": [
        "The vast majority of the time, we will use functions from pre-built libraries, such as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0Okq3aHKmNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the python sys library\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rufTFm_KmNT",
        "colab_type": "text"
      },
      "source": [
        "You can check your Python version at the command line by running:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KinzRTPKKmNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine the python system version\n",
        "sys.version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1Ibx51NKmNX",
        "colab_type": "text"
      },
      "source": [
        "You can't import every library on the lab environment due to security issues. However, you can import most of the common scientific ones. Here we import the libraries `numpy` (https://www.numpy.org) and `pandas` (https://pandas.pydata.org), two of the most common and useful libraries in data science. We recommend copying this import statement for every new notebook that you will create."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaOLEYluKmNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the number and pandas data science libraries\n",
        "import numpy\n",
        "import pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hYQ3Pf8KmNa",
        "colab_type": "text"
      },
      "source": [
        "Let's now use the numpy library to calculate the mean of a list of numbers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xEvf0kNKmNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numpy.mean([1, 2, 3, 4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0oq_ImSKmNd",
        "colab_type": "text"
      },
      "source": [
        "Notice that you can rename libraries to whatever you want after importing. The as statement allows this. Here we use `np` and `pd` as aliases for both the pre-built numpy and pandas libraries. This is very common aliasing and will be found in most code snippets around the web. The idea behind this is to allow you to type fewer characters when you are frequently accessing these libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6baxY1f8KmNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the numpy and pandas data science libraries using aliases\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAypmu8WKmNh",
        "colab_type": "text"
      },
      "source": [
        "Let's now use the numpy library to calculate the mean of a list of numbers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_44DJdSKmNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean([1, 2, 3, 4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hXAkKYeKmNm",
        "colab_type": "text"
      },
      "source": [
        "### 3. Code Completion and Documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIEmigi4KmNn",
        "colab_type": "text"
      },
      "source": [
        "#### Autocomplete Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwNmDlSXKmNp",
        "colab_type": "text"
      },
      "source": [
        "Pressing tab will give you a list of Jupyter's best guesses for what you might want to type next. This is incredibly valuable and will save you a lot of time. If there is only one possible option for what you could type next, Jupyter will fill that in for you. Try pressing tab very frequently; it will seldom fill in anything you don't want, as if there is ambiguity a list will be shown. This is a great way to see what functions are available in a library.\n",
        "\n",
        "Try placing your cursor after the . and press the `tab` key on your keyboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywP7vIXxKmNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.gamma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlfTxm4nKmNs",
        "colab_type": "text"
      },
      "source": [
        "#### Documentation Help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz63zkBrKmNu",
        "colab_type": "text"
      },
      "source": [
        "Placing a question mark after a function and executing that line of code will give you the documentation Jupyter has for that function. It's often best to do this in a new cell, as you avoid re-executing other code and running into bugs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TZH7GnhKmNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.normal?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rU9Z2z-KmNy",
        "colab_type": "text"
      },
      "source": [
        "### 4. Plotting Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uw2pKrgKmNz",
        "colab_type": "text"
      },
      "source": [
        "#### Random Data Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxL4jOO9KmN0",
        "colab_type": "text"
      },
      "source": [
        "Let's' sample some random data using a function from numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMQmpOxKKmN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample 100 points with a mean of 0 and an std of 1. This is a standard normal distribution.\n",
        "x = np.random.normal(0, 1, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQg4WrFuKmN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXomV6SYKmN5",
        "colab_type": "text"
      },
      "source": [
        "#### Data Plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYt4pz6dKmN6",
        "colab_type": "text"
      },
      "source": [
        "Python's `Matplotlib` library (https://matplotlib.org) is a very flexible library and has a lot of handy, built-in defaults that will help you out tremendously. \n",
        "\n",
        "As such, you donâ€™t need much to get started: you need to make the necessary imports, prepare some data, and you can start plotting with the help of the `plot()` function. Let's have a look."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCEOhim9KmN7",
        "colab_type": "text"
      },
      "source": [
        "Let's import Matplotlib by running the following statements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vjHT7JZKmN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the matplotlib plotting library\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgcUCqyxKmN_",
        "colab_type": "text"
      },
      "source": [
        "Note that we imported the `pyplot` module of the `Matplotlib` library under the alias `plt`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvxWWLRZKmOA",
        "colab_type": "text"
      },
      "source": [
        "We can now use the plotting functionality provided by Matplotlib as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvbGylz5KmOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qemP3FwqKmOE",
        "colab_type": "text"
      },
      "source": [
        "Let's apply some variations as well as the axis legends to our plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "C3BFUkhQKmOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x, linewidth=3, linestyle=\"--\")\n",
        "\n",
        "# set label and title details\n",
        "plt.xlabel('sample', weight='normal', fontsize=8)\n",
        "plt.ylabel('value', weight='normal', fontsize=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv3hU2Q_KmOH",
        "colab_type": "text"
      },
      "source": [
        "#### Remove Line Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drp2rBIZKmOI",
        "colab_type": "text"
      },
      "source": [
        "You might have noticed a similar annoying line of the form: `[<matplotlib.lines.Line2D at 0x10a4cce90>]` before the created plot. If you wish to get rid of this output just end you plot statement using a semicolon `;`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY4B5zRHKmOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mp8LZjEKmOM",
        "colab_type": "text"
      },
      "source": [
        "#### Adding Axis Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK0vyOmtKmON",
        "colab_type": "text"
      },
      "source": [
        "No self-respecting quantitative analyst leaves a graph without labeled axes. Here are some commands to help with that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qO62qozKmOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample 100 points twice with a mean of 0 and an std of 1 from a standard normal distribution.\n",
        "x1 = np.random.normal(0, 1, 100)\n",
        "x2 = np.random.normal(0, 1, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWY4RGNVKmOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot both sample results\n",
        "plt.plot(x1);\n",
        "plt.plot(x2);\n",
        "\n",
        "# add x-axis and y-axis label \n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Returns')\n",
        "\n",
        "# add plot legend\n",
        "plt.legend(['X1', 'X2'])\n",
        "\n",
        "# add plot title\n",
        "plt.title('Sample Returns X1 and X2');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yeu1gyZjKmOV",
        "colab_type": "text"
      },
      "source": [
        "### 5. Generating Statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMsbuC3zKmOW",
        "colab_type": "text"
      },
      "source": [
        "Let's use `numpy` to take some simple statistics like the mean of the generated samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOAXvA-4KmOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(x1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygTvYeIGKmOZ",
        "colab_type": "text"
      },
      "source": [
        "and their corresponding standard deviation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7bwNts-KmOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.std(x1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuJz8AMJKmOc",
        "colab_type": "text"
      },
      "source": [
        "### 6. Collect and Plot Real Pricing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UsFpXO7KmOd",
        "colab_type": "text"
      },
      "source": [
        "One of the first steps to any data science project is usually to import your data. Randomly sampled data can be great for testing ideas, but let's now import some real financial market data. \n",
        "\n",
        "As part of the `Labs` section of the **Intro into ML and DL** Git repository, you will find a \"Comma Separated Value (CSV)\" file named `sample_google_data_daily.csv`. The file contains the daily stock market data of the **Alphabet (Google) Inc.** stock within the time frame `31-12-2015` till `31-12-2017`. Pls. download the data and copy it to the same directory as this Jupyter Notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO_7_ph4KmOd",
        "colab_type": "text"
      },
      "source": [
        "One you completed the download you're ready to import the file into Python using the `read_csv()` function of the `pandas` library by running the following statement:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU5GyIS5KmOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_url = 'https://raw.githubusercontent.com/GitiHubi/courseMLDL/master/lab_01/sample_google_data_daily.csv'\n",
        "alphabet_data = pd.read_csv(data_url, sep=';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg9K9ToAKmOh",
        "colab_type": "text"
      },
      "source": [
        "The retrieved data is a so-called `pandas` `DataFrame`. You can see the datetime index and the columns with different pricing data. Let's inspect the top 5 rows of the imported data using the `head()` function of the `pandas` library: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERZMtEfYKmOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphabet_data.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-q6chwUKmOt",
        "colab_type": "text"
      },
      "source": [
        "Looks good, right?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4C13aIfKmOx",
        "colab_type": "text"
      },
      "source": [
        "It's great to import data that was already collected and stored accordingly. Unfortunately, in real data science projects, we are often challenged to retrieve the data from a variety of sources, e.g., the web. But where to get financial data of good quality? A great source for retrieving such data can be found in `Quandl`(https://www.quandl.com). `Quandl` is a platform for financial, economic, and alternative data. \n",
        "\n",
        "A nice feature of `Quandl` is that a lot of their data is accessible through packages for multiple programming languages, including Python. Let's give it a try and retrieve some market data using `Quandl`. \n",
        "\n",
        "Although the 'Azure' as well as the 'Colab' environment come with a lot of pre-installed libraries, sometimes a needed library might not be available. Therefore, you may want to install libraries directly within an individual notebook. Please note, libraries installed from the notebook apply only to the current server session. Library installations aren't persisted once the server is shut down.\n",
        "\n",
        "In general, libraries in Python can be installed using the **pip** command within code cells. Let's give it a try and install the `quandl` python library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOtpfp9JKmO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install quandl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vSLPFa5KmO2",
        "colab_type": "text"
      },
      "source": [
        "Once the `quandl` library is successfully installed, let's import it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpJiEu1wKmO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import quandl as ql\n",
        "import datetime as dt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AflH0FaQKmO7",
        "colab_type": "text"
      },
      "source": [
        "Init the `Quandl` financial data download API and set your corresponding `Quandl` API key:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAGQUBmKKmO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ql.ApiConfig.api_key = '<enter you own quandl api code here>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDbFP16bKmO9",
        "colab_type": "text"
      },
      "source": [
        "Specify both the `start` and `end` date of the data download:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woTiDUvUKmO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_date = dt.datetime(2015, 12, 31)\n",
        "end_date = dt.datetime(2017, 12, 31)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxWTZjVRKmPA",
        "colab_type": "text"
      },
      "source": [
        "Download the daily **Tesla Inc.** (ticker symbol: TSLA) stock data using the `.get` method of the `Quandl's` financial data library: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uneBBsdLKmPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download tesla market data\n",
        "tesla_data = ql.get('WIKI/TSLA', start_date=start_date, end_date=end_date, collapse='daily')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPzUA-7AKmPD",
        "colab_type": "text"
      },
      "source": [
        "We again retrieved the data as a `pandas` `dataframe` but this time using the `Quandl` data library. Let's inspect the top 5 rows of the imported data using the `head()` function of the `pandas` library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0CeECeIKmPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tesla_data.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58iSUcTbKmPJ",
        "colab_type": "text"
      },
      "source": [
        "To obtain an initial understanding of the date retrieved let us have a look at some basic data statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKYKtfrdKmPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tesla_data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba9B5BIRKmPL",
        "colab_type": "text"
      },
      "source": [
        "Ok, at a first glance the data looks fine. Let's therefore save it to your local directory using the `to_csv()` function of the `pandas` library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrZyRk65KmPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tesla_data.to_csv('sample_tesla_data_daily.csv', sep=';', encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqQB3rweKmPO",
        "colab_type": "text"
      },
      "source": [
        "Let's continue with the **Alphabet Inc.** data prepared. In order to get a specific column of a pandas dataframe, we can column-slice it to just get the daily adjusted closing price data like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtoPot01KmPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tesla_closing = tesla_data['Adj. Close']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9pcseTYKmPQ",
        "colab_type": "text"
      },
      "source": [
        "Let's inspect the top 5 rows of the sliced data: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpyOSGhIKmPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tesla_closing.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLUwxq5GKmPV",
        "colab_type": "text"
      },
      "source": [
        "Ok, great we got two columns (1) the index 'Date' of the DataFrame as well as (2) the data column 'Adj. Close' price that we asked for. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTaN_xcXKmPV",
        "colab_type": "text"
      },
      "source": [
        "Let's now plot the date vs. the adjusted closing prices. But before doing so we need to be able to disentangle the index from the data. This can be accomplished by the `.index` function that will return the index of a given DataFrame as well as the `.values` function that will return the actual data (excl. the index) of a given DataFrame. We will use both commands to specify the X and Y coordinates of the plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3IHrnwpKmPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot both sample results\n",
        "plt.plot(pd.to_datetime(tesla_closing.index), tesla_closing.values)\n",
        "\n",
        "# add x-axis and y-axis label \n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Closing Price')\n",
        "\n",
        "# add plot title\n",
        "plt.title('Tesla Inc. Daily Adjusted Closing Price');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNrIIuL5KmPX",
        "colab_type": "text"
      },
      "source": [
        "We can furthermore use the `.values` function to obtain statistics of individual columns of a DataFrame. Let's get some further statistics (mean and standard deviation) of the Tesla Inc. daily adjusted closing price data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs2CNyxQKmPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(tesla_closing.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JT6XzkyKmPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.std(tesla_closing.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB4-nrsnKmPa",
        "colab_type": "text"
      },
      "source": [
        "### 7. Obtaining Returns from Prices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGjjW9t4KmPa",
        "colab_type": "text"
      },
      "source": [
        "When analyzing stock market data, we are often also interested in the return $R_t$ of a financial instrument over a certain time frame:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am-ef4NZKmPb",
        "colab_type": "text"
      },
      "source": [
        "$$R_t=\\frac{V_{f}-V_{i}}{V_{i}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTmstK2uKmPb",
        "colab_type": "text"
      },
      "source": [
        "where:\n",
        "\n",
        "- $V_{f}$ denotes the financial instruments final value, including dividends and interest\n",
        "- $V_{i}$ denotes the financial instruments initial value\n",
        "\n",
        "The `Pandas` data science library provides us with a variety of functions that come quite \"handy\" when analyzing such data. To determine the daily return $r_t$ we may, for example, utilize Pandas `pct_change` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fYJS4hkKmPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tesla_returns = tesla_closing.pct_change()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EignqjSZKmPg",
        "colab_type": "text"
      },
      "source": [
        "Let's inspect the calculated returns: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MeZ8cZwKmPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tesla_returns.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KThY5w2GKmPi",
        "colab_type": "text"
      },
      "source": [
        "Notice, how we drop the first element after doing this, as it will be `NaN`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4yz-E6oKmPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tesla_returns = tesla_returns[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po5ZhtR4KmPm",
        "colab_type": "text"
      },
      "source": [
        "And inspect the returns data again:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMWbSo3wKmPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tesla_returns.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMtSzWvKKmPo",
        "colab_type": "text"
      },
      "source": [
        "Let's now plot the distribution of daily returns as a histogram:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU2pAO-vKmPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot histogram of returns\n",
        "plt.hist(tesla_returns, bins=20)\n",
        "\n",
        "# add x-axis and y-axis label \n",
        "plt.xlabel('Return')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# add plot title\n",
        "plt.title('Alphabet Inc. Adjusted Daily Returns');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0CZOVOEKmPu",
        "colab_type": "text"
      },
      "source": [
        "Let's again get statistics on the real daily return data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNqCFRIZKmPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(tesla_returns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LuJJ3JVKmPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.std(tesla_returns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cwE7SzpKmPy",
        "colab_type": "text"
      },
      "source": [
        "Let's generate data out of a normal distribution using the statistics we estimated from the daily returns of the Tesla stock. We'll see that we have good reason to suspect the Tesla returns may not be normally distributed, as the resulting normal distribution looks far different."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Dvyw0IKmPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot histogram of randomly sampled returns\n",
        "plt.hist(np.random.normal(np.mean(tesla_returns), np.std(tesla_returns), 10000), bins=20)\n",
        "\n",
        "# add x-axis and y-axis label \n",
        "plt.xlabel('Return')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# add plot title\n",
        "plt.title('Tesla Inc. Adjusted Daily Returns (Normal)');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IHVNAyjKmP3",
        "colab_type": "text"
      },
      "source": [
        "### 8. Generating a Moving Average "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwhaa8wXKmP3",
        "colab_type": "text"
      },
      "source": [
        "When analyzing stock market data, we are often also interested in calculating so called \"rolling statistics\", e.g., a 90- or 200-day moving average. Again the `pandas` library is offering some great functions that allow us to generate such rolling statistics. Here's an example. Notice how there's no moving average for the first 30 days, as we don't have 90 days before we can determine the first value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yeh-HMU4KmP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine the rolling average of the last 90 days\n",
        "tesla_moving_average = tesla_closing.rolling(window=90, center=False).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tY2lmeoKmP5",
        "colab_type": "text"
      },
      "source": [
        "Let's plot the obtained moving averages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o7qwE-UKmP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot quarterly returns\n",
        "plt.plot(tesla_closing.index, tesla_closing.values)\n",
        "\n",
        "# plot moving averages quarterly returns\n",
        "plt.plot(tesla_moving_average.index, tesla_moving_average.values)\n",
        "\n",
        "# add x-axis and y-axis label \n",
        "plt.xlabel('Return')\n",
        "plt.ylabel('Price')\n",
        "\n",
        "# add plot legend\n",
        "plt.legend(['Return', '90-day MAVG']);\n",
        "\n",
        "# add plot title\n",
        "plt.title('Tesla Inc. Returns vs. Moving Average Returns');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aK6gWCcKmP7",
        "colab_type": "text"
      },
      "source": [
        "### Lab Assignments:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdGS4meOKmP8",
        "colab_type": "text"
      },
      "source": [
        "Quandl is a platform for financial, economic, and alternative data that provides investment professionals with a variety of distinct datasets. Thereby, Quandl sources data from several distinct data publishers. All of Quandl's financial data is accessible via an 'Application Programming Interface' (API). Let's learn how data from Quandl can be retrieved:\n",
        "\n",
        "**1. Registration for a Quandl API key ( https://www.quandl.com/ ).** \n",
        "\n",
        "> Visit the`Quandl` webpage (https://www.quandl.com/) and sign up for an Academic account (indicating that you will use the data solely in an academic environment). Once you did register, you will receive an API key that can be used to download financial data provided by `Quandl`. The API key will be displayed once you logged in to `Quandl` under `'Account Settings'` -> `'API key'`.\n",
        "\n",
        "**2. Download data using the Quandl API, `ql.get(..., collapse=...)`.**\n",
        "\n",
        "> Research the`Quandl` API and download the daily closing prices (instead of the quarterly) of the three following stocks: Netflix, Facebook, and Snapchat. Download the daily stock closing prices starting from 2014-01-01 until today as a `Pandas` DataFrame.\n",
        "\n",
        "Throughout the course, we will visualize and analyze plenty of data. The following exercises should provide you a first intuition on how this can be achieved using Python's `Pandas` and `Matplotlib` library: \n",
        "\n",
        "**3. Visualise data using the `Matplotlib` library, `plt.plot(...)` and `plt.hist(...)`.**\n",
        "\n",
        "> Visualize the downloaded data by plotting the daily adjusted closing prices of the three stocks over time (1) into a single plot for each stock as well as (2) into a single plot containing the closing prices of all three stocks combined.\n",
        "\n",
        "**4. Save data using the `Pandas` library.**\n",
        "\n",
        "> Research the `Panda's` data science library on how to save a pandas DataFrame to a local directory. Save the raw daily closing prices and corresponding date of all three stocks in a comma-separated value (CSV) format to your local directory. Save the CSV file using the semicolon `';'` separator and encode it as `'utf-8'`.\n",
        "\n",
        "\n",
        "**5. Analyse data using the `Pandas` library, `data.rolling(..., window=...)`.**\n",
        "\n",
        "> For each stock, calculate the rolling moving averages of the daily closing prices using a time window of 30 and 90 days. For each stock plot the daily closing price as well as the 30 and 90 days moving average into a single plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4zNYuPCKmP8",
        "colab_type": "text"
      },
      "source": [
        "### Lab Summary:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynWbXIzCKmP9",
        "colab_type": "text"
      },
      "source": [
        "In this initial lab, a step by step introduction into some basic concepts of analyzing financial data using Jupyter notebooks are presented. The code and exercises presented in this lab may serve your as a starting point for more complex and tailored analytics. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud-i_kk1KmP9",
        "colab_type": "text"
      },
      "source": [
        "You may want to execute the content of your lab outside of the Jupyter notebook environment, e.g., on a compute node or a server. The cell below converts the lab notebook into a standalone and executable python script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex8nzfMhKmP9",
        "colab_type": "code",
        "outputId": "87290db8-869f-473b-8f5f-47f1f5b6cefd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!jupyter nbconvert --to script mldl_lab_01.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NbConvertApp] WARNING | pattern u'mldl_lab_01.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb) to various other\n",
            "formats.\n",
            "\n",
            "WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "-------\n",
            "\n",
            "Arguments that take values are actually convenience aliases to full\n",
            "Configurables, whose aliases are listed on the help line. For more information\n",
            "on full configurables, see '--help-all'.\n",
            "\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document. \n",
            "    This mode is ideal for generating code-free reports.\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only \n",
            "    relevant when converting to notebook format)\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "--clear-output\n",
            "    Clear output of current file and save in place, \n",
            "    overwriting the existing notebook.\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "--generate-config\n",
            "    generate default config file\n",
            "--nbformat=<Enum> (NotebookExporter.nbformat_version)\n",
            "    Default: 4\n",
            "    Choices: [1, 2, 3, 4]\n",
            "    The nbformat version to write. Use this to downgrade notebooks.\n",
            "--output-dir=<Unicode> (FilesWriter.build_directory)\n",
            "    Default: ''\n",
            "    Directory to write output(s) to. Defaults to output to the directory of each\n",
            "    notebook. To recover previous default behaviour (outputting to the current\n",
            "    working directory) use . as the flag value.\n",
            "--writer=<DottedObjectName> (NbConvertApp.writer_class)\n",
            "    Default: 'FilesWriter'\n",
            "    Writer class used to write the  results of the conversion\n",
            "--log-level=<Enum> (Application.log_level)\n",
            "    Default: 30\n",
            "    Choices: (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL')\n",
            "    Set the log level by value or name.\n",
            "--reveal-prefix=<Unicode> (SlidesExporter.reveal_url_prefix)\n",
            "    Default: u''\n",
            "    The URL prefix for reveal.js (version 3.x). This defaults to the reveal CDN,\n",
            "    but can be any url pointing to a copy  of reveal.js.\n",
            "    For speaker notes to work, this must be a relative path to a local  copy of\n",
            "    reveal.js: e.g., \"reveal.js\".\n",
            "    If a relative path is given, it must be a subdirectory of the current\n",
            "    directory (from which the server is run).\n",
            "    See the usage documentation\n",
            "    (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-\n",
            "    slideshow) for more details.\n",
            "--to=<Unicode> (NbConvertApp.export_format)\n",
            "    Default: 'html'\n",
            "    The export format to be used, either one of the built-in formats\n",
            "    ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf',\n",
            "    'python', 'rst', 'script', 'slides'] or a dotted object name that represents\n",
            "    the import path for an `Exporter` class\n",
            "--template=<Unicode> (TemplateExporter.template_file)\n",
            "    Default: u''\n",
            "    Name of the template file to use\n",
            "--output=<Unicode> (NbConvertApp.output_base)\n",
            "    Default: ''\n",
            "    overwrite base name use for output files. can only be used when converting\n",
            "    one notebook at a time.\n",
            "--post=<DottedOrNone> (NbConvertApp.postprocessor_class)\n",
            "    Default: u''\n",
            "    PostProcessor class used to write the results of the conversion\n",
            "--config=<Unicode> (JupyterApp.config_file)\n",
            "    Default: u''\n",
            "    Full path of a config file.\n",
            "\n",
            "To see all available configurables, use `--help-all`\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb\n",
            "    \n",
            "    which will convert mynotebook.ipynb to the default format (probably HTML).\n",
            "    \n",
            "    You can specify the export format with `--to`.\n",
            "    Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides'].\n",
            "    \n",
            "    > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "    \n",
            "    Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "    'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
            "    can specify the flavor of the format used.\n",
            "    \n",
            "    > jupyter nbconvert --to html --template basic mynotebook.ipynb\n",
            "    \n",
            "    You can also pipe the output to stdout, rather than a file\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "    \n",
            "    PDF is generated via latex\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "    \n",
            "    You can get (and serve) a Reveal.js-powered slideshow\n",
            "    \n",
            "    > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "    \n",
            "    Multiple notebooks can be given at the command line in a couple of \n",
            "    different ways:\n",
            "    \n",
            "    > jupyter nbconvert notebook*.ipynb\n",
            "    > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "    \n",
            "    or you can specify the notebooks list in a config file, containing::\n",
            "    \n",
            "        c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "    \n",
            "    > jupyter nbconvert --config mycfg.py\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}